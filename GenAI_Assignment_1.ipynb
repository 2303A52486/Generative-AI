{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPGZYBCB9rotscBY2GEVdus",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/2303A52486/Generative-AI/blob/main/GenAI_Assignment_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "V.Abhinav(2303A52486)"
      ],
      "metadata": {
        "id": "cfHNyBTNsq3S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Write Python code from scratch to find error metrics of deep learning model. Actual values and deep learning model predicted values are shown in Table-1. Also compare the results with the outcomes of libraries"
      ],
      "metadata": {
        "id": "74PX3T9DuK0B"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EvopQEv-qGad",
        "outputId": "1ad26993-4323-47fb-80a4-ae0ba24ca518"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Absolute Error (MAE): 0.4600000000000016\n",
            "Mean Squared Error (MSE): 0.24600000000000147\n",
            "R-squared (R²): 0.99877\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "\n",
        "Actual = np.array([20, 30, 40, 50, 60])\n",
        "Pred = np.array([20.5, 30.3, 40.2, 50.6, 60.7])\n",
        "\n",
        "# Calculating Manually\n",
        "\n",
        "# 1. MAE\n",
        "mae = np.mean(np.abs(Actual - Pred))\n",
        "print(f\"Mean Absolute Error (MAE): {mae}\")\n",
        "\n",
        "# 2. MSE\n",
        "mse = np.mean((Actual - Pred) ** 2)\n",
        "print(f\"Mean Squared Error (MSE): {mse}\")\n",
        "\n",
        "# 3. R-Squared\n",
        "ss_total = np.sum((Actual - np.mean(Actual)) ** 2)\n",
        "ss_residual = np.sum((Actual - Pred) ** 2)\n",
        "r2 = 1 - (ss_residual / ss_total)\n",
        "print(f\"R-squared (R²): {r2}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#  Calulating with scikit-learn Library\n",
        "\n",
        "# MAE using sklearn\n",
        "mae_sk = mean_absolute_error(Actual, Pred)\n",
        "print(f\"MAE (sklearn): {mae_sk}\")\n",
        "\n",
        "# MSE using sklearn\n",
        "mse_sk = mean_squared_error(Actual, Pred)\n",
        "print(f\"MSE (sklearn): {mse_sk}\")\n",
        "\n",
        "# R² using sklearn\n",
        "r2_sk = r2_score(Actual, Pred)\n",
        "print(f\"R-squared (sklearn): {r2_sk}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_--4tIBmujXA",
        "outputId": "b79692bb-778a-4329-b5c3-c05221618ad0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MAE (sklearn): 0.4600000000000016\n",
            "MSE (sklearn): 0.24600000000000147\n",
            "R-squared (sklearn): 0.99877\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Write python code from scratch to find evaluation metrics of deep learning model.\n",
        "Actual values and deep learning model predicted values are shown in Table 2. Also compare the\n",
        "results with outcome of libraries"
      ],
      "metadata": {
        "id": "nyvUlRfdBNIz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "def compute_metrics(y_true, y_pred):\n",
        "    total = len(y_true)\n",
        "    correct = sum(y_t == y_p for y_t, y_p in zip(y_true, y_pred))\n",
        "    accuracy = correct / total\n",
        "\n",
        "    precision = precision_score(y_true, y_pred, average=None, zero_division=0)\n",
        "    recall = recall_score(y_true, y_pred, average=None, zero_division=0)\n",
        "    f1 = f1_score(y_true, y_pred, average=None, zero_division=0)\n",
        "\n",
        "    return accuracy, precision, recall, f1\n",
        "\n",
        "y_actual = np.array([0, 0, 0, 0, 0, 1, 0, 2, 1, 2, 2, 0, 2, 2, 1])\n",
        "y_pred = np.array([0, 0, 1, 1, 2, 0, 1, 0, 1, 2, 2, 1, 0, 2, 2])\n",
        "\n",
        "accuracy, precision, recall, f1 = compute_metrics(y_actual, y_pred)\n",
        "\n",
        "print(\"Results:\")\n",
        "print(f\"Accuracy: {accuracy:.2f}\")\n",
        "print(f\"Precision: {precision}\")\n",
        "print(f\"Recall: {recall}\")\n",
        "print(f\"F1 Score: {f1}\")\n",
        "\n",
        "# Using sklearn for verification\n",
        "print(\"\\nUsing sklearn:\")\n",
        "print(f\"Accuracy: {accuracy_score(y_actual, y_pred):.2f}\")\n",
        "print(f\"Precision: {precision_score(y_actual, y_pred, average=None, zero_division=0)}\")\n",
        "print(f\"Recall: {recall_score(y_actual, y_pred, average=None, zero_division=0)}\")\n",
        "print(f\"F1 Score: {f1_score(y_actual, y_pred, average=None, zero_division=0)}\")\n"
      ],
      "metadata": {
        "id": "Lwivi2QyBbbR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dec2f6ca-5a26-4c82-ef81-bddc4dad7ce0"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results:\n",
            "Accuracy: 0.40\n",
            "Precision: [0.4 0.2 0.6]\n",
            "Recall: [0.28571429 0.33333333 0.6       ]\n",
            "F1 Score: [0.33333333 0.25       0.6       ]\n",
            "\n",
            "Using sklearn:\n",
            "Accuracy: 0.40\n",
            "Precision: [0.4 0.2 0.6]\n",
            "Recall: [0.28571429 0.33333333 0.6       ]\n",
            "F1 Score: [0.33333333 0.25       0.6       ]\n"
          ]
        }
      ]
    }
  ]
}